{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6장. 지지 벡터 머신\n",
    "## 학습 목표\n",
    " - 지지 벡터 머신 소개\n",
    " - 최적화를 위한 SMO 알고리즘\n",
    " - 데이터 '변형'을 위해 커널 사용하기\n",
    " - 다른 분류와 지지 벡터 머신 비교하기\n",
    " \n",
    "## 6.1 최대 마진으로 데이터 분리하기\n",
    " - 장점: 일반화의 오류가 낮음, 계산 비용이 적음, 결과 해석이 쉬움\n",
    " - 단점: 매개변수의 조정과 커널 선택에 민감함(본래 이진 분리만을 다룸)\n",
    " - 활용: 수치형 값, 명목형 값\n",
    " <br><br>\n",
    " - 초평면 분리(separating hyperplane) : 데이터 집합을 분리하는 것 \n",
    "   <br>따라서 2D 플롯에서는 하나의 선이 되지만 3차원 데이터 집합에서 데이터를 분리하기 위해서는 하나의 평면이 필요함\n",
    " - 초평면(hyperplane) : n차원 공간에서 초평면은 (n-1)차원의 집합이며 초평면은 의사 결정 범위(decision boundary)가 됨\n",
    " <br>\n",
    " <br>\n",
    " - 선형으로 분리되지 않는 데이터 집합 예제\n",
    " <img src = 'figure6_1.PNG' width=400 height=400>\n",
    " <br>\n",
    " - 선형 분리(linear separable)가 가능한 데이터 예제\n",
    " <img src = 'figure6_2.PNG' width=400 height=400>\n",
    " - B,C,D 중에서 가장 좋은 것은 D임\n",
    " > 초평면 분리에 가장 가까운 지점을 찾기를 원하면서도 이 지점이 가능한 한 분리선에서 멀리 떨어져 있기를 원함<br>\n",
    " > 마진이 가능한 한 가장 커야 함<br>\n",
    " > 실수를 하거나 한정된 데이터로 분류기를 훈련시키고자 할 때에도 분류기가 최대한 튼튼하기를 원하기 때문\n",
    " - 지지 벡터 : 초평면 분리에 가장 가까운 지점\n",
    " - 분리선에서 지지 벡터가지의 거리를 가장 크게 해야 함\n",
    " \n",
    "## 6.2 최대 마진 찾기\n",
    " - 초평면 분리는 w^Tx+b로부터 얻어짐\n",
    " - 만약 점 A에서 분리면까지의 거리를 구하고자 한다면, 선에 직각 또는 수직인 선의 길이를 측정해야 함\n",
    " - 이러한 측정은 |w^Tx+b|/||w||으로 구할 수 있음\n",
    " - 상수 b는 단지 로지스틱 회귀에서 w0처럼 오프셋(offset)임\n",
    " - 여기서 w와 b는 데이터를 위한 분리선 또는 초평면을 묘사하는 것\n",
    " <img src = 'figure6_3.PNG' width=300 height=300>\n",
    " - 점 A에서 분리면까지의 거리는 분리면에 수직인 하나의 선에 의해 측정됨\n",
    " \n",
    "### 6.2.1 분류기 관점에서의 최적화 문제 구성하기\n",
    " - 분류항목의 계산 : w^Tx+b < 0 이면 f(w^Tx+b)=-1 w^Tx+b >= 0 이면 f(w^Tx+b)=1\n",
    " - 마진의 계산 : label*(w^Tx+b)\n",
    " - 마진이 가장 작은 점을 찾으면 그 마진을 최대화해야 함 : <img src='maxMargin.PNG' width=300 height=150>\n",
    " - 제약 조건 : label*(w^Tx+b)이 1.0 또는 이보다 더 큰 값이 되어야 함\n",
    " - 이러한 제약적인 최적화 문제를 해결하기 위해 라그랑지 곱수(Lagrange multipliers)를 사용함 : \n",
    " <img src='lagrangeMultipliers.PNG' width=300 height=150>\n",
    " 위 식은 다음과 같은 제약 조건을 따름\n",
    " <img src='constraint.PNG' width=200 height=100>\n",
    " 그러나 이것은 데이터가 선형분리된다는 가정이 필요함\n",
    " - 여유 변수(slack variable)로 의사 결정 범위에 속하지 않는 예제를 허용할 수 있음\n",
    " - 여유 변수를 도입시킨 새로운 제약 조건 : <img src='slackConstraint.PNG' width=200 height=100>\n",
    " 상수 c는 마진을 크게 만들고자 하는 목표와 대부분의 예제가 기능적인 1.0 이상의 마진을 갖도록 보장하는 것 사이에서 가중치를 조절\n",
    " <br> 상수 c는 최적화 코드의 인자이므로 변경 가능하며 그에 따라 다른 결과를 얻을 수 있음\n",
    " - 이제 알파를 해결하면 알파의 관점에서 분리 초평면을 표현 가능\n",
    " - SVMs에서 대부분의 작업이 알파를 찾는 것임\n",
    " \n",
    "### 6.2.2 일반적인 기본 구조로 지지 벡터 머신에 접근하기\n",
    " - SVMs의 일반적인 접근\n",
    " > 1. 수집: 모든 방법\n",
    " > 2. 준비: 수치형 값\n",
    " > 3. 분석: 분리 초평면을 시각화하는 데 도움이 됨\n",
    " > 4. 훈련: 대부분의 시간을 이 단계에 소비. 두 개의 매개변수는 이번 단계가 진행되는 동안 조정될 수 있음\n",
    " > 5. 검사: 매우 간단한 계산임\n",
    " > 6. 사용: 거의 모든 분류 문제에 SVMs를 사용할 수 있으나 SVMs는 이진 분류기 이므로 3개 이상의 분류항목인 경우 수정이 필요함\n",
    " \n",
    "## 6.3 SMO 알고리즘으로 효율적인 최적화하기\n",
    " - 이차 방정식 솔버(quadratic solver): 선형적인 제약 조건이 있는 여러 변수를 가지고 이차 방정식 함수를 최적화하는 소프트웨어의 한 부분\n",
    "### 6.3.1 플랫의 SMO 알고리즘\n",
    " - 1996년 존 플랫(John Platt)이 지지 벡터 머신을 훈련시키기 위해 SMO라는 알고리즘을 발표함\n",
    " - SMO는 순차적 최소 최적화(Sequential Minimal Optimization)의 약어\n",
    " - SMO 알고리즘은 알파와 b의 집합을 찾는 것 -> 알파의 집합을 구하게 되면 가중치 w는 쉽게 계산되며 분리 초평면을 구할 수 있음\n",
    " - SMO 알고리즘의 동작 :\n",
    "  > 각각의 사이클을 최적화하기 위해 두 개의 알파를 선택\n",
    "  > 적당한 알파의 쌍을 찾게 되면, 그 중 하나는 값을 증가시키고 하나는 줄임\n",
    "  > 적당한 알파를 구하기 위해서는 알파 집합이 조건을 정확하게 충족해야 함: \n",
    "      > - 알파 쌍 모두가 그들의 마진 경계 밖에 있어야 함\n",
    "      > - 알파가 이미 고정되어 있거나 경계를 갖지 않아야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2 간략한 형태의 SMO로 적은 양의 데이터 집합 해결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6.1 SMO 알고리즘을 위한 도움 함수\n",
    "\n",
    "def loadDataSet(fileName):\n",
    "    dataMat=[]; labelMat=[]\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        lineArr = line.strip().split('\\t')\n",
    "        dataMat.append([float(lineArr[0]), float(lineArr[1])])\n",
    "        labelMat.append(float(lineArr[2]))\n",
    "    return dataMat, labelMat\n",
    "\n",
    "def selectJrand(i, m):\n",
    "    j=i\n",
    "    while(j==i):\n",
    "        j=int(random.uniform(0,m))\n",
    "    return j\n",
    "\n",
    "def clipAlpha(aj, H, L):\n",
    "    if aj > H:\n",
    "        aj = H\n",
    "    if L > aj:\n",
    "        aj = L\n",
    "    return aj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 전체 플랫 SMO를 이용해 최적화 속도 올리기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
